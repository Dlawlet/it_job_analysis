{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7afbb1",
   "metadata": {},
   "source": [
    "# üáßüá™ Belgium IT Jobs Market Analysis Report 2025\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This comprehensive analysis examines the Belgium IT job market based on **242 Indeed job postings** scraped on June 27, 2025. The report provides insights into:\n",
    "\n",
    "- **Market Overview**: Job distribution, top employers, and geographic concentration\n",
    "- **Skills Demand**: Most sought-after technical and soft skills\n",
    "- **Language Requirements**: Multilingual demands in the Belgian market\n",
    "- **Regional Insights**: Brussels vs Flanders vs Wallonia job distribution\n",
    "- **Market Trends**: Temporal patterns and growth areas\n",
    "- **Seniority Analysis**: Experience level requirements and career opportunities\n",
    "\n",
    "### Key Findings (Preview)\n",
    "- **Total Jobs Analyzed**: 242 IT positions from 77 unique companies\n",
    "- **Geographic Distribution**: Brussels-Capital (38%), Other/Remote (41.7%), Flanders (17.4%), Wallonia (2.9%)\n",
    "- **Market Concentration**: Top 10 companies account for significant portion of openings\n",
    "- **Data Quality**: 100% job description coverage, limited salary transparency (0.4%)\n",
    "- **Temporal Patterns**: Strong recent activity with diverse posting schedule\n",
    "- **Role Diversity**: 224 unique job titles indicating market specialization\n",
    "\n",
    "### Report Highlights\n",
    "üè¢ **Market Structure**: Balanced between Brussels concentration and distributed opportunities  \n",
    "üåç **Linguistic Landscape**: Multi-language requirements reflecting Belgium's diversity  \n",
    "‚öôÔ∏è **Technical Focus**: Modern tech stack with cloud, development, and data emphasis  \n",
    "üëî **Experience Levels**: Opportunities across junior to senior career stages  \n",
    "üìä **Data Insights**: Comprehensive analysis despite limited salary data availability\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e857f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (first time only)\n",
    "# !pip install pandas matplotlib seaborn wordcloud nltk spacy scikit-learn plotly folium\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud \n",
    "import nltk\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load data\n",
    "print(\"üìä Loading Belgium IT Jobs Dataset...\")\n",
    "df = pd.read_csv(\"dataset_indeed-scraper_2025-06-27_14-14-35-957.csv\")\n",
    "\n",
    "# Belgium-specific preprocessing\n",
    "def standardize_belgian_locations(location):\n",
    "    \"\"\"Standardize Belgian city names and regions\"\"\"\n",
    "    if pd.isna(location):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    location = str(location).strip().title()\n",
    "    \n",
    "    # Map common variations to standard names\n",
    "    location_mapping = {\n",
    "        'Bruxelles': 'Brussels', 'Brussel': 'Brussels', 'Brussels-Capital': 'Brussels',\n",
    "        'Antwerpen': 'Antwerp', 'Anvers': 'Antwerp',\n",
    "        'Gent': 'Ghent', 'Gand': 'Ghent',\n",
    "        'Li√®ge': 'Liege', 'Luik': 'Liege',\n",
    "        'Namur': 'Namur', 'Namen': 'Namur',\n",
    "        'Leuven': 'Leuven', 'Louvain': 'Leuven',\n",
    "        'Charleroi': 'Charleroi',\n",
    "        'Mons': 'Mons', 'Bergen': 'Mons',\n",
    "        'Mechelen': 'Mechelen', 'Malines': 'Mechelen'\n",
    "    }\n",
    "    \n",
    "    for variation, standard in location_mapping.items():\n",
    "        if variation in location:\n",
    "            return standard\n",
    "    \n",
    "    return location\n",
    "\n",
    "# Apply location standardization\n",
    "df['location_clean'] = df['location'].apply(standardize_belgian_locations)\n",
    "\n",
    "# Add Belgian regions\n",
    "def get_belgian_region(location):\n",
    "    \"\"\"Categorize cities by Belgian region\"\"\"\n",
    "    if pd.isna(location):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    location = str(location).lower()\n",
    "    \n",
    "    # Brussels-Capital Region\n",
    "    if any(city in location for city in ['brussels', 'bruxelles', 'brussel']):\n",
    "        return 'Brussels-Capital'\n",
    "    \n",
    "    # Flanders (Dutch-speaking)\n",
    "    flanders_cities = ['antwerp', 'ghent', 'bruges', 'leuven', 'mechelen', 'hasselt', \n",
    "                      'sint-niklaas', 'kortrijk', 'ostend', 'genk', 'turnhout']\n",
    "    if any(city in location for city in flanders_cities):\n",
    "        return 'Flanders'\n",
    "    \n",
    "    # Wallonia (French-speaking)\n",
    "    wallonia_cities = ['liege', 'charleroi', 'namur', 'mons', 'tournai', 'verviers', \n",
    "                      'seraing', 'mouscron', 'la louvi√®re', 'wavre']\n",
    "    if any(city in location for city in wallonia_cities):\n",
    "        return 'Wallonia'\n",
    "    \n",
    "    return 'Other/Remote'\n",
    "\n",
    "df['region'] = df['location_clean'].apply(get_belgian_region)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df):,} job postings\")\n",
    "print(f\"üìÖ Data collected: {df['scrapedAt'].iloc[0]}\")\n",
    "print(f\"üè¢ Unique companies: {df['company'].nunique():,}\")\n",
    "print(f\"üèôÔ∏è Unique locations: {df['location'].nunique():,}\")\n",
    "\n",
    "# Show sample with enhanced info\n",
    "df[['company', 'positionName', 'location_clean', 'region', 'salary']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ecca02",
   "metadata": {},
   "source": [
    "## üìã Data Quality Assessment\n",
    "\n",
    "Understanding the quality and completeness of our dataset is crucial for reliable analysis. This section examines data coverage, missing values, and potential biases in our Belgium IT jobs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic stats\n",
    "print(\"\\nUnique companies:\", df['company'].nunique())\n",
    "print(\"Unique job locations:\", df['location'].nunique())\n",
    "print(\"Unique job titles:\", df['positionName'].nunique())\n",
    "\n",
    "# Distribution over time\n",
    "df['postingDateParsed'] = pd.to_datetime(df['postingDateParsed'], errors='coerce')\n",
    "df['scrapedAt'] = pd.to_datetime(df['scrapedAt'], errors='coerce')\n",
    "\n",
    "df['postingDateParsed'].hist(bins=30, figsize=(10,4))\n",
    "plt.title(\"Job Postings Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Postings\")\n",
    "plt.show()\n",
    "\n",
    "# Dataset Overview\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"Date range: {df['postingDateParsed'].min()} to {df['postingDateParsed'].max()}\")\n",
    "print(f\"Scraping date: {df['scrapedAt'].iloc[0]}\")\n",
    "\n",
    "# Missing values analysis\n",
    "print(\"\\nüîç MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_pct = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing %': missing_pct\n",
    "}).sort_values('Missing %', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Data completeness by key fields\n",
    "key_fields = ['company', 'positionName', 'location', 'description', 'salary']\n",
    "completeness = {}\n",
    "for field in key_fields:\n",
    "    if field in df.columns:\n",
    "        complete_pct = ((len(df) - df[field].isnull().sum()) / len(df)) * 100\n",
    "        completeness[field] = complete_pct\n",
    "\n",
    "completeness_df = pd.DataFrame(list(completeness.items()), \n",
    "                              columns=['Field', 'Completeness %'])\n",
    "\n",
    "# Regional distribution\n",
    "print(\"\\nüèõÔ∏è REGIONAL DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "region_dist = df['region'].value_counts()\n",
    "region_pct = (region_dist / len(df)) * 100\n",
    "for region, count in region_dist.items():\n",
    "    print(f\"{region}: {count:,} jobs ({region_pct[region]:.1f}%)\")\n",
    "\n",
    "# Date distribution analysis\n",
    "df['postingDateParsed'] = pd.to_datetime(df['postingDateParsed'], errors='coerce')\n",
    "df['posting_weekday'] = df['postingDateParsed'].dt.day_name()\n",
    "df['posting_week'] = df['postingDateParsed'].dt.isocalendar().week\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Data completeness\n",
    "completeness_df.set_index('Field')['Completeness %'].plot(kind='bar', \n",
    "                                                          ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Data Completeness by Key Fields')\n",
    "axes[0,0].set_ylabel('Completeness %')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Regional distribution\n",
    "region_dist.plot(kind='pie', ax=axes[0,1], autopct='%1.1f%%')\n",
    "axes[0,1].set_title('Job Distribution by Belgian Region')\n",
    "\n",
    "# 3. Posting timeline\n",
    "df['postingDateParsed'].hist(bins=30, ax=axes[1,0], color='lightgreen', alpha=0.7)\n",
    "axes[1,0].set_title('Job Postings Timeline')\n",
    "axes[1,0].set_xlabel('Date')\n",
    "axes[1,0].set_ylabel('Number of Postings')\n",
    "\n",
    "# 4. Weekly pattern\n",
    "weekday_counts = df['posting_weekday'].value_counts()\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_counts = weekday_counts.reindex(weekday_order, fill_value=0)\n",
    "weekday_counts.plot(kind='bar', ax=axes[1,1], color='coral')\n",
    "axes[1,1].set_title('Job Postings by Day of Week')\n",
    "axes[1,1].set_ylabel('Number of Postings')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìà KEY STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"‚Ä¢ Unique companies: {df['company'].nunique():,}\")\n",
    "print(f\"‚Ä¢ Unique job titles: {df['positionName'].nunique():,}\")\n",
    "print(f\"‚Ä¢ Jobs with salary info: {df['salary'].notna().sum():,} ({(df['salary'].notna().sum()/len(df)*100):.1f}%)\")\n",
    "print(f\"‚Ä¢ Jobs with descriptions: {df['description'].notna().sum():,} ({(df['description'].notna().sum()/len(df)*100):.1f}%)\")\n",
    "print(f\"‚Ä¢ Average description length: {df['description'].str.len().mean():.0f} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f2b14",
   "metadata": {},
   "source": [
    "## üè¢ Market Overview: Companies, Roles & Locations\n",
    "\n",
    "This section analyzes the key players in Belgium's IT job market, examining top hiring companies, most in-demand job titles, and geographic distribution across Belgian cities and regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common job titles\n",
    "df['positionName'].value_counts().head(20).plot(kind='barh', figsize=(8,6))\n",
    "plt.title(\"Top 20 Job Titles\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Most hiring companies\n",
    "df['company'].value_counts().head(20).plot(kind='barh', figsize=(8,6), color='green')\n",
    "plt.title(\"Top 20 Hiring Companies\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Most frequent cities\n",
    "df['location'].value_counts().head(20).plot(kind='barh', figsize=(8,6), color='purple')\n",
    "plt.title(\"Top 20 Cities for IT Jobs in Belgium\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Enhanced Market Overview Analysis\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Top 15 Job Titles', 'Top 15 Hiring Companies', \n",
    "                   'Geographic Distribution', 'Belgian Regions Overview'),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"pie\"}]]\n",
    ")\n",
    "\n",
    "# 1. Top Job Titles\n",
    "top_titles = df['positionName'].value_counts().head(15)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_titles.values, y=top_titles.index, orientation='h',\n",
    "           name='Job Titles', marker_color='lightblue'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Top Companies\n",
    "top_companies = df['company'].value_counts().head(15)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_companies.values, y=top_companies.index, orientation='h',\n",
    "           name='Companies', marker_color='lightgreen'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Top Cities\n",
    "top_cities = df['location_clean'].value_counts().head(15)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_cities.values, y=top_cities.index, orientation='h',\n",
    "           name='Cities', marker_color='lightcoral'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Regional Distribution\n",
    "region_counts = df['region'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=region_counts.index, values=region_counts.values,\n",
    "           name='Regions'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, showlegend=False, \n",
    "                 title_text=\"Belgium IT Job Market Overview\")\n",
    "fig.show()\n",
    "\n",
    "# Detailed Analysis\n",
    "print(\"üéØ TOP JOB TITLES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Most common job title: '{top_titles.index[0]}' ({top_titles.iloc[0]} positions)\")\n",
    "\n",
    "# Categorize job titles\n",
    "developer_roles = df[df['positionName'].str.contains('Developer|Engineer|Programmer', case=False, na=False)]\n",
    "analyst_roles = df[df['positionName'].str.contains('Analyst|Analysis', case=False, na=False)]\n",
    "manager_roles = df[df['positionName'].str.contains('Manager|Lead|Director', case=False, na=False)]\n",
    "consultant_roles = df[df['positionName'].str.contains('Consultant|Advisor', case=False, na=False)]\n",
    "\n",
    "role_categories = {\n",
    "    'Development/Engineering': len(developer_roles),\n",
    "    'Analysis': len(analyst_roles),\n",
    "    'Management/Leadership': len(manager_roles),\n",
    "    'Consulting': len(consultant_roles),\n",
    "    'Other': len(df) - len(developer_roles) - len(analyst_roles) - len(manager_roles) - len(consultant_roles)\n",
    "}\n",
    "\n",
    "print(\"\\nüìä JOB CATEGORY BREAKDOWN\")\n",
    "for category, count in role_categories.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {category}: {count:,} positions ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüè¢ COMPANY INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total unique companies: {df['company'].nunique():,}\")\n",
    "print(f\"Companies with 10+ postings: {sum(df['company'].value_counts() >= 10)}\")\n",
    "print(f\"Companies with 5+ postings: {sum(df['company'].value_counts() >= 5)}\")\n",
    "\n",
    "# Company diversity index (companies needed for 50% of jobs)\n",
    "company_counts = df['company'].value_counts()\n",
    "cumsum = company_counts.cumsum()\n",
    "companies_for_50pct = len(cumsum[cumsum <= len(df) * 0.5])\n",
    "print(f\"Companies needed for 50% of jobs: {companies_for_50pct} ({(companies_for_50pct/df['company'].nunique()*100):.1f}% of all companies)\")\n",
    "\n",
    "print(f\"\\nüèõÔ∏è REGIONAL INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "for region in region_counts.index:\n",
    "    count = region_counts[region]\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {region}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "# Brussels vs Rest of Belgium\n",
    "brussels_jobs = len(df[df['region'] == 'Brussels-Capital'])\n",
    "other_jobs = len(df) - brussels_jobs\n",
    "print(f\"\\nüìç Brussels vs Rest of Belgium:\")\n",
    "print(f\"‚Ä¢ Brussels-Capital: {brussels_jobs:,} jobs ({(brussels_jobs/len(df)*100):.1f}%)\")\n",
    "print(f\"‚Ä¢ Rest of Belgium: {other_jobs:,} jobs ({(other_jobs/len(df)*100):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56bb580",
   "metadata": {},
   "source": [
    "## üî§ Job Description Analysis\n",
    "\n",
    "Exploring the most commonly mentioned terms, skills, and requirements in Belgium IT job descriptions through text analysis and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212191b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Text Analysis for Belgium IT Jobs\n",
    "def clean_text_belgium(text):\n",
    "    \"\"\"Enhanced text cleaning for Belgian job market\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs and email addresses\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Keep important punctuation for compound terms\n",
    "    text = re.sub(r'[^\\w\\s\\-\\.\\+#]', ' ', text)\n",
    "    \n",
    "    # Handle common tech terms\n",
    "    text = re.sub(r'\\bc\\+\\+\\b', 'cplusplus', text)\n",
    "    text = re.sub(r'\\bc#\\b', 'csharp', text)\n",
    "    text = re.sub(r'\\bf#\\b', 'fsharp', text)\n",
    "    text = re.sub(r'\\.net\\b', 'dotnet', text)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "df['clean_description'] = df['description'].apply(clean_text_belgium)\n",
    "\n",
    "# Belgium-specific stopwords (Dutch, French, German, English)\n",
    "belgian_stopwords = set(stopwords.words('english')) | set(stopwords.words('dutch')) | set(stopwords.words('french')) | set(stopwords.words('german'))\n",
    "\n",
    "# Add common job posting stopwords\n",
    "job_stopwords = {\n",
    "    'job', 'position', 'role', 'opportunity', 'candidate', 'applicant', 'company', 'team', 'work', 'experience',\n",
    "    'years', 'year', 'strong', 'good', 'excellent', 'looking', 'seeking', 'requirements', 'responsibilities',\n",
    "    'skills', 'knowledge', 'ability', 'working', 'nbsp', 'li', 'ul', 'div', 'br', 'span', 'p',\n",
    "    'de', 'het', 'en', 'van', 'je', 'voor', 'met', 'op', 'als', 'een', 'binnen', 'onze',  # Dutch\n",
    "    'le', 'la', 'les', 'du', 'des', 'et', 'avec', 'sur', 'dans', 'pour', 'notre', 'vous',  # French\n",
    "    'der', 'die', 'das', 'und', 'mit', 'f√ºr', 'bei', 'von', 'zu', 'auf', 'unser'  # German\n",
    "}\n",
    "\n",
    "all_stopwords = belgian_stopwords | job_stopwords\n",
    "\n",
    "# Create multiple visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "# 1. General WordCloud\n",
    "text_data = ' '.join(df['clean_description'].dropna())\n",
    "wordcloud_general = WordCloud(\n",
    "    stopwords=all_stopwords,\n",
    "    background_color='white',\n",
    "    max_words=150,\n",
    "    width=800, height=400,\n",
    "    colormap='viridis'\n",
    ").generate(text_data)\n",
    "\n",
    "axes[0,0].imshow(wordcloud_general, interpolation='bilinear')\n",
    "axes[0,0].axis('off')\n",
    "axes[0,0].set_title(\"Most Common Terms in Belgium IT Job Descriptions\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Tech-focused WordCloud\n",
    "tech_terms = []\n",
    "for desc in df['clean_description'].dropna():\n",
    "    # Extract tech-related terms using regex patterns\n",
    "    tech_patterns = [\n",
    "        r'\\b[a-z]*script\\b',  # javascript, typescript, etc.\n",
    "        r'\\b[a-z]*sql\\b',     # mysql, postgresql, etc.\n",
    "        r'\\b[a-z]*[0-9]+\\b',  # java8, python3, etc.\n",
    "        r'\\b\\w*framework\\b',   # framework terms\n",
    "        r'\\b\\w*api\\b',        # API terms\n",
    "        r'\\b\\w*cloud\\b',      # cloud terms\n",
    "    ]\n",
    "    \n",
    "    for pattern in tech_patterns:\n",
    "        matches = re.findall(pattern, desc)\n",
    "        tech_terms.extend(matches)\n",
    "\n",
    "tech_text = ' '.join(tech_terms + text_data.split())\n",
    "wordcloud_tech = WordCloud(\n",
    "    stopwords=all_stopwords | {'framework', 'api', 'cloud', 'script'},\n",
    "    background_color='white',\n",
    "    max_words=100,\n",
    "    width=800, height=400,\n",
    "    colormap='plasma'\n",
    ").generate(tech_text)\n",
    "\n",
    "axes[0,1].imshow(wordcloud_tech, interpolation='bilinear')\n",
    "axes[0,1].axis('off')\n",
    "axes[0,1].set_title(\"Technology-Focused Terms\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Most common single words\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words=list(all_stopwords),\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=30,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "word_freq = vectorizer.fit_transform(df['clean_description'].dropna())\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "word_counts = word_freq.sum(axis=0).A1\n",
    "\n",
    "word_freq_df = pd.DataFrame({\n",
    "    'word': feature_names,\n",
    "    'count': word_counts\n",
    "}).sort_values('count', ascending=True)\n",
    "\n",
    "word_freq_df.plot(x='word', y='count', kind='barh', ax=axes[1,0], color='lightblue')\n",
    "axes[1,0].set_title('Top 30 Most Frequent Terms')\n",
    "axes[1,0].set_xlabel('Frequency')\n",
    "\n",
    "# 4. Most common bigrams (2-word phrases)\n",
    "vectorizer_bigram = CountVectorizer(\n",
    "    stop_words=list(all_stopwords),\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=20,\n",
    "    min_df=3\n",
    ")\n",
    "\n",
    "bigram_freq = vectorizer_bigram.fit_transform(df['clean_description'].dropna())\n",
    "bigram_names = vectorizer_bigram.get_feature_names_out()\n",
    "bigram_counts = bigram_freq.sum(axis=0).A1\n",
    "\n",
    "bigram_df = pd.DataFrame({\n",
    "    'bigram': bigram_names,\n",
    "    'count': bigram_counts\n",
    "}).sort_values('count', ascending=True)\n",
    "\n",
    "bigram_df.plot(x='bigram', y='count', kind='barh', ax=axes[1,1], color='lightcoral')\n",
    "axes[1,1].set_title('Top 20 Most Frequent Phrases (2-words)')\n",
    "axes[1,1].set_xlabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Text analysis insights\n",
    "print(\"üìù TEXT ANALYSIS INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total words analyzed: {len(text_data.split()):,}\")\n",
    "print(f\"Unique words (after cleaning): {len(set(text_data.split())):,}\")\n",
    "print(f\"Average job description length: {df['clean_description'].str.split().str.len().mean():.0f} words\")\n",
    "\n",
    "print(f\"\\nTop 10 Most Frequent Terms:\")\n",
    "for i, row in word_freq_df.tail(10).iterrows():\n",
    "    print(f\"‚Ä¢ {row['word']}: {row['count']} mentions\")\n",
    "\n",
    "print(f\"\\nTop 5 Most Frequent Phrases:\")\n",
    "for i, row in bigram_df.tail(5).iterrows():\n",
    "    print(f\"‚Ä¢ '{row['bigram']}': {row['count']} mentions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b142a3",
   "metadata": {},
   "source": [
    "## üëî Seniority & Experience Analysis\n",
    "\n",
    "Analysis of job seniority levels in the Belgium IT market, examining the distribution of junior, mid-level, and senior positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_seniority(text):\n",
    "    text = text.lower()\n",
    "    if 'senior' in text or 'lead' in text:\n",
    "        return 'Senior'\n",
    "    elif 'junior' in text or 'graduate' in text or 'entry level' in text:\n",
    "        return 'Junior'\n",
    "    else:\n",
    "        return 'Unspecified'\n",
    "\n",
    "df['seniority'] = df['clean_description'].apply(detect_seniority)\n",
    "\n",
    "sns.countplot(data=df, x='seniority', order=['Junior', 'Senior', 'Unspecified'])\n",
    "plt.title(\"Job Seniority Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Enhanced Seniority Analysis\n",
    "def detect_seniority_comprehensive(title, description):\n",
    "    \"\"\"Comprehensive seniority detection using both title and description\"\"\"\n",
    "    text = f\"{str(title)} {str(description)}\".lower()\n",
    "    \n",
    "    # Senior level indicators\n",
    "    senior_keywords = [\n",
    "        'senior', 'lead', 'principal', 'architect', 'expert', 'specialist',\n",
    "        'head of', 'chief', 'director', 'manager', 'team lead', 'technical lead',\n",
    "        '5+ years', '6+ years', '7+ years', '8+ years', '9+ years', '10+ years',\n",
    "        'experienced', 'advanced'\n",
    "    ]\n",
    "    \n",
    "    # Junior level indicators\n",
    "    junior_keywords = [\n",
    "        'junior', 'graduate', 'entry level', 'entry-level', 'intern', 'trainee',\n",
    "        'fresh graduate', 'new graduate', 'recent graduate', 'beginner',\n",
    "        '0-2 years', '1-2 years', 'no experience required'\n",
    "    ]\n",
    "    \n",
    "    # Mid-level indicators\n",
    "    mid_keywords = [\n",
    "        'mid-level', 'intermediate', 'regular', 'medior',\n",
    "        '2-5 years', '3-5 years', '2-4 years', '3-4 years'\n",
    "    ]\n",
    "    \n",
    "    # Check for keywords\n",
    "    senior_score = sum(1 for keyword in senior_keywords if keyword in text)\n",
    "    junior_score = sum(1 for keyword in junior_keywords if keyword in text)\n",
    "    mid_score = sum(1 for keyword in mid_keywords if keyword in text)\n",
    "    \n",
    "    # Determine seniority\n",
    "    if senior_score > 0 and senior_score >= junior_score:\n",
    "        return 'Senior'\n",
    "    elif junior_score > 0 and junior_score >= mid_score:\n",
    "        return 'Junior'\n",
    "    elif mid_score > 0:\n",
    "        return 'Mid-Level'\n",
    "    else:\n",
    "        return 'Not Specified'\n",
    "\n",
    "# Apply enhanced seniority detection\n",
    "df['seniority_enhanced'] = df.apply(lambda row: detect_seniority_comprehensive(\n",
    "    row['positionName'], row['description']), axis=1)\n",
    "\n",
    "# Extract years of experience mentioned\n",
    "def extract_experience_years(text):\n",
    "    \"\"\"Extract mentioned years of experience\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Look for patterns like \"5+ years\", \"3-5 years\", etc.\n",
    "    patterns = [\n",
    "        r'(\\d+)\\+?\\s*years?',\n",
    "        r'(\\d+)\\s*to\\s*(\\d+)\\s*years?',\n",
    "        r'(\\d+)\\s*-\\s*(\\d+)\\s*years?'\n",
    "    ]\n",
    "    \n",
    "    years = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        for match in matches:\n",
    "            if isinstance(match, tuple):\n",
    "                years.extend([int(x) for x in match if x.isdigit()])\n",
    "            else:\n",
    "                years.append(int(match))\n",
    "    \n",
    "    return max(years) if years else None\n",
    "\n",
    "df['experience_years'] = df['description'].apply(extract_experience_years)\n",
    "\n",
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Seniority distribution\n",
    "seniority_counts = df['seniority_enhanced'].value_counts()\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "seniority_counts.plot(kind='pie', ax=axes[0,0], autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[0,0].set_title('Job Seniority Distribution')\n",
    "axes[0,0].set_ylabel('')\n",
    "\n",
    "# 2. Seniority by region\n",
    "if 'region' in df.columns:\n",
    "    seniority_region = pd.crosstab(df['region'], df['seniority_enhanced'], normalize='index') * 100\n",
    "    seniority_region.plot(kind='bar', ax=axes[0,1], stacked=True, color=colors)\n",
    "    axes[0,1].set_title('Seniority Distribution by Region (%)')\n",
    "    axes[0,1].set_ylabel('Percentage')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 3. Experience years distribution\n",
    "exp_data = df[df['experience_years'].notna()]\n",
    "if len(exp_data) > 0:\n",
    "    exp_data['experience_years'].hist(bins=range(0, 16), ax=axes[1,0], alpha=0.7, color='lightgreen')\n",
    "    axes[1,0].set_title('Required Years of Experience Distribution')\n",
    "    axes[1,0].set_xlabel('Years of Experience')\n",
    "    axes[1,0].set_ylabel('Number of Jobs')\n",
    "    axes[1,0].axvline(exp_data['experience_years'].median(), color='red', linestyle='--', \n",
    "                     label=f'Median: {exp_data[\"experience_years\"].median():.1f} years')\n",
    "    axes[1,0].legend()\n",
    "\n",
    "# 4. Seniority vs Job Categories\n",
    "job_categories = []\n",
    "for title in df['positionName']:\n",
    "    title_lower = str(title).lower()\n",
    "    if any(word in title_lower for word in ['developer', 'engineer', 'programmer']):\n",
    "        job_categories.append('Development')\n",
    "    elif any(word in title_lower for word in ['analyst', 'analysis']):\n",
    "        job_categories.append('Analysis')\n",
    "    elif any(word in title_lower for word in ['manager', 'director', 'lead']):\n",
    "        job_categories.append('Management')\n",
    "    elif any(word in title_lower for word in ['consultant', 'advisor']):\n",
    "        job_categories.append('Consulting')\n",
    "    elif any(word in title_lower for word in ['devops', 'sysadmin', 'infrastructure']):\n",
    "        job_categories.append('DevOps/Infra')\n",
    "    else:\n",
    "        job_categories.append('Other')\n",
    "\n",
    "df['job_category'] = job_categories\n",
    "\n",
    "category_seniority = pd.crosstab(df['job_category'], df['seniority_enhanced'], normalize='index') * 100\n",
    "category_seniority.plot(kind='bar', ax=axes[1,1], color=colors)\n",
    "axes[1,1].set_title('Seniority by Job Category (%)')\n",
    "axes[1,1].set_ylabel('Percentage')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed insights\n",
    "print(\"üéØ SENIORITY INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"Overall Seniority Distribution:\")\n",
    "for level, count in seniority_counts.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {level}: {count:,} positions ({pct:.1f}%)\")\n",
    "\n",
    "if len(exp_data) > 0:\n",
    "    print(f\"\\nExperience Requirements (based on {len(exp_data)} jobs with clear requirements):\")\n",
    "    print(f\"‚Ä¢ Average required experience: {exp_data['experience_years'].mean():.1f} years\")\n",
    "    print(f\"‚Ä¢ Median required experience: {exp_data['experience_years'].median():.1f} years\")\n",
    "    print(f\"‚Ä¢ Most common requirement: {exp_data['experience_years'].mode().iloc[0]} years\")\n",
    "    \n",
    "    # Experience distribution\n",
    "    exp_dist = exp_data['experience_years'].value_counts().sort_index()\n",
    "    print(f\"\\nExperience Distribution:\")\n",
    "    for years, count in exp_dist.head(8).items():\n",
    "        print(f\"‚Ä¢ {years} years: {count} jobs\")\n",
    "\n",
    "print(f\"\\nJob Category Distribution:\")\n",
    "cat_counts = df['job_category'].value_counts()\n",
    "for category, count in cat_counts.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {category}: {count:,} positions ({pct:.1f}%)\")\n",
    "\n",
    "# Regional seniority insights\n",
    "if 'region' in df.columns:\n",
    "    print(f\"\\nRegional Seniority Patterns:\")\n",
    "    for region in df['region'].unique():\n",
    "        if region != 'Unknown':\n",
    "            region_data = df[df['region'] == region]\n",
    "            senior_pct = (region_data['seniority_enhanced'] == 'Senior').mean() * 100\n",
    "            junior_pct = (region_data['seniority_enhanced'] == 'Junior').mean() * 100\n",
    "            print(f\"‚Ä¢ {region}: {senior_pct:.1f}% Senior, {junior_pct:.1f}% Junior\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2aa34",
   "metadata": {},
   "source": [
    "## üåç Language Requirements Analysis\n",
    "\n",
    "Belgium's multilingual landscape creates unique language requirements for IT professionals. This analysis examines the linguistic demands across different regions and job types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4886aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Language Analysis for Belgium\n",
    "def detect_language_requirements(text):\n",
    "    \"\"\"Detect specific language requirements in job descriptions\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {}\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Language patterns with variations\n",
    "    language_patterns = {\n",
    "        'Dutch': [\n",
    "            'dutch', 'nederlands', 'flemish', 'vlaams', 'nl', 'nederlands sprekend',\n",
    "            'nederlandse taal', 'vlaamse', 'flemish speaking'\n",
    "        ],\n",
    "        'French': [\n",
    "            'french', 'fran√ßais', 'francais', 'fr', 'french speaking',\n",
    "            'langue fran√ßaise', 'francophone'\n",
    "        ],\n",
    "        'English': [\n",
    "            'english', 'engels', 'anglais', 'en', 'english speaking',\n",
    "            'fluent english', 'business english'\n",
    "        ],\n",
    "        'German': [\n",
    "            'german', 'deutsch', 'allemand', 'de', 'german speaking',\n",
    "            'deutsche sprache'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Proficiency levels\n",
    "    proficiency_patterns = {\n",
    "        'Native': ['native', 'moedertaal', 'langue maternelle', 'muttersprache'],\n",
    "        'Fluent': ['fluent', 'vlot', 'couramment', 'flie√üend', 'excellent'],\n",
    "        'Business': ['business level', 'professional', 'zakelijk', 'professionnel'],\n",
    "        'Conversational': ['conversational', 'gesprek', 'conversation', 'unterhalten'],\n",
    "        'Basic': ['basic', 'basis', 'basique', 'grundlegend']\n",
    "    }\n",
    "    \n",
    "    # Multilingual indicators\n",
    "    multilingual_patterns = [\n",
    "        'bilingual', 'trilingual', 'multilingual', 'tweetalig', 'drietalig', 'meertalig',\n",
    "        'bilingue', 'trilingue', 'multilingue', 'zweisprachig', 'dreisprachig', 'mehrsprachig'\n",
    "    ]\n",
    "    \n",
    "    detected = {}\n",
    "    \n",
    "    # Check for specific languages\n",
    "    for language, patterns in language_patterns.items():\n",
    "        if any(pattern in text for pattern in patterns):\n",
    "            detected[language] = True\n",
    "            \n",
    "            # Check proficiency level\n",
    "            for level, level_patterns in proficiency_patterns.items():\n",
    "                if any(pattern in text for pattern in level_patterns):\n",
    "                    detected[f'{language}_level'] = level\n",
    "                    break\n",
    "    \n",
    "    # Check for multilingual requirements\n",
    "    if any(pattern in text for pattern in multilingual_patterns):\n",
    "        detected['Multilingual'] = True\n",
    "    \n",
    "    return detected\n",
    "\n",
    "# Apply language detection\n",
    "language_requirements = df['description'].apply(detect_language_requirements)\n",
    "\n",
    "# Extract language data\n",
    "languages = ['Dutch', 'French', 'English', 'German', 'Multilingual']\n",
    "for lang in languages:\n",
    "    df[f'requires_{lang.lower()}'] = language_requirements.apply(lambda x: x.get(lang, False))\n",
    "\n",
    "# Language combinations analysis\n",
    "df['language_count'] = df[[f'requires_{lang.lower()}' for lang in languages[:4]]].sum(axis=1)\n",
    "df['monolingual'] = df['language_count'] == 1\n",
    "df['bilingual_plus'] = df['language_count'] >= 2\n",
    "\n",
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Language requirements overview\n",
    "lang_counts = {}\n",
    "for lang in languages:\n",
    "    lang_counts[lang] = df[f'requires_{lang.lower()}'].sum()\n",
    "\n",
    "lang_series = pd.Series(lang_counts).sort_values(ascending=True)\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#F7DC6F']\n",
    "lang_series.plot(kind='barh', ax=axes[0,0], color=colors)\n",
    "axes[0,0].set_title('Language Requirements in Belgium IT Jobs')\n",
    "axes[0,0].set_xlabel('Number of Job Postings')\n",
    "\n",
    "# 2. Language requirements by region\n",
    "if 'region' in df.columns:\n",
    "    lang_by_region = pd.DataFrame()\n",
    "    for region in df['region'].unique():\n",
    "        if region != 'Unknown':\n",
    "            region_data = df[df['region'] == region]\n",
    "            lang_stats = {}\n",
    "            for lang in languages[:4]:  # Exclude 'Multilingual' for clarity\n",
    "                lang_stats[lang] = region_data[f'requires_{lang.lower()}'].mean() * 100\n",
    "            lang_by_region[region] = lang_stats\n",
    "    \n",
    "    lang_by_region.plot(kind='bar', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Language Requirements by Region (%)')\n",
    "    axes[0,1].set_ylabel('Percentage of Jobs')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 3. Multilingual requirements distribution\n",
    "multilingual_data = df['language_count'].value_counts().sort_index()\n",
    "multilingual_data.plot(kind='bar', ax=axes[1,0], color='lightcoral')\n",
    "axes[1,0].set_title('Number of Languages Required per Job')\n",
    "axes[1,0].set_xlabel('Number of Languages')\n",
    "axes[1,0].set_ylabel('Number of Jobs')\n",
    "\n",
    "# 4. Language combinations\n",
    "# Most common language combinations\n",
    "lang_combinations = []\n",
    "for _, row in df.iterrows():\n",
    "    combo = []\n",
    "    for lang in languages[:4]:\n",
    "        if row[f'requires_{lang.lower()}']:\n",
    "            combo.append(lang)\n",
    "    if combo:\n",
    "        lang_combinations.append(' + '.join(sorted(combo)))\n",
    "    else:\n",
    "        lang_combinations.append('Not Specified')\n",
    "\n",
    "combo_counts = pd.Series(lang_combinations).value_counts().head(10)\n",
    "combo_counts.plot(kind='barh', ax=axes[1,1], color='lightgreen')\n",
    "axes[1,1].set_title('Top 10 Language Combinations')\n",
    "axes[1,1].set_xlabel('Number of Jobs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interactive visualization with Plotly\n",
    "fig_interactive = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Language Requirements Distribution', 'Regional Language Patterns',\n",
    "                   'Language Proficiency Analysis', 'Multilingual Job Trends'),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"pie\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "# Add interactive plots\n",
    "lang_series_interactive = pd.Series(lang_counts)\n",
    "fig_interactive.add_trace(\n",
    "    go.Bar(x=lang_series_interactive.values, y=lang_series_interactive.index, \n",
    "           orientation='h', name='Languages'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Detailed language insights\n",
    "print(\"üåç LANGUAGE REQUIREMENTS INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"Overall Language Requirements:\")\n",
    "total_jobs = len(df)\n",
    "for lang in languages:\n",
    "    count = df[f'requires_{lang.lower()}'].sum()\n",
    "    pct = (count / total_jobs) * 100\n",
    "    print(f\"‚Ä¢ {lang}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nLanguage Patterns:\")\n",
    "print(f\"‚Ä¢ Jobs requiring only 1 language: {df['monolingual'].sum():,} ({(df['monolingual'].sum()/total_jobs*100):.1f}%)\")\n",
    "print(f\"‚Ä¢ Jobs requiring 2+ languages: {df['bilingual_plus'].sum():,} ({(df['bilingual_plus'].sum()/total_jobs*100):.1f}%)\")\n",
    "print(f\"‚Ä¢ Jobs with no specific language requirements: {(df['language_count'] == 0).sum():,} ({((df['language_count'] == 0).sum()/total_jobs*100):.1f}%)\")\n",
    "\n",
    "print(f\"\\nMost Common Language Combinations:\")\n",
    "for combo, count in combo_counts.head(5).items():\n",
    "    pct = (count / total_jobs) * 100\n",
    "    print(f\"‚Ä¢ {combo}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "# Regional language analysis\n",
    "if 'region' in df.columns:\n",
    "    print(f\"\\nRegional Language Patterns:\")\n",
    "    for region in ['Brussels-Capital', 'Flanders', 'Wallonia']:\n",
    "        if region in df['region'].values:\n",
    "            region_data = df[df['region'] == region]\n",
    "            print(f\"\\n{region} ({len(region_data):,} jobs):\")\n",
    "            \n",
    "            for lang in ['Dutch', 'French', 'English']:\n",
    "                count = region_data[f'requires_{lang.lower()}'].sum()\n",
    "                pct = (count / len(region_data)) * 100\n",
    "                print(f\"  ‚Ä¢ {lang}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "# Belgium-specific insights\n",
    "print(f\"\\nüáßüá™ BELGIUM-SPECIFIC INSIGHTS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Dutch vs French requirements\n",
    "dutch_jobs = df['requires_dutch'].sum()\n",
    "french_jobs = df['requires_french'].sum()\n",
    "print(f\"‚Ä¢ Dutch requirement: {dutch_jobs:,} jobs\")\n",
    "print(f\"‚Ä¢ French requirement: {french_jobs:,} jobs\")\n",
    "print(f\"‚Ä¢ Dutch/French ratio: {dutch_jobs/french_jobs:.2f}:1\" if french_jobs > 0 else \"‚Ä¢ Dutch/French ratio: N/A\")\n",
    "\n",
    "# Trilingual (Dutch + French + English) jobs\n",
    "trilingual_belgium = df[\n",
    "    df['requires_dutch'] & \n",
    "    df['requires_french'] & \n",
    "    df['requires_english']\n",
    "].shape[0]\n",
    "print(f\"‚Ä¢ Trilingual (NL+FR+EN) jobs: {trilingual_belgium:,} ({(trilingual_belgium/total_jobs*100):.1f}%)\")\n",
    "\n",
    "# English dominance\n",
    "english_only = df[df['requires_english'] & (df['language_count'] == 1)].shape[0]\n",
    "print(f\"‚Ä¢ English-only jobs: {english_only:,} ({(english_only/total_jobs*100):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80fac0",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Technical Skills Demand Analysis\n",
    "\n",
    "Comprehensive analysis of the most sought-after technical skills, programming languages, frameworks, and tools in Belgium's IT job market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92acadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Technical Skills Analysis\n",
    "\n",
    "# Extended skill categories for Belgium IT market\n",
    "skill_categories = {\n",
    "    'Programming Languages': {\n",
    "        'python': ['python', 'py'],\n",
    "        'java': ['java', 'openjdk'],\n",
    "        'javascript': ['javascript', 'js', 'ecmascript'],\n",
    "        'typescript': ['typescript', 'ts'],\n",
    "        'csharp': ['c#', 'csharp', 'c sharp', 'dotnet', '.net'],\n",
    "        'cpp': ['c++', 'cplusplus', 'cpp'],\n",
    "        'php': ['php'],\n",
    "        'go': ['golang', 'go lang'],\n",
    "        'rust': ['rust'],\n",
    "        'kotlin': ['kotlin'],\n",
    "        'swift': ['swift'],\n",
    "        'ruby': ['ruby'],\n",
    "        'scala': ['scala'],\n",
    "        'r': [r'\\br\\b'],\n",
    "        'matlab': ['matlab']\n",
    "    },\n",
    "    'Web Technologies': {\n",
    "        'react': ['react', 'reactjs', 'react.js'],\n",
    "        'angular': ['angular', 'angularjs'],\n",
    "        'vue': ['vue', 'vuejs', 'vue.js'],\n",
    "        'nodejs': ['node.js', 'nodejs', 'node js'],\n",
    "        'html': ['html', 'html5'],\n",
    "        'css': ['css', 'css3'],\n",
    "        'bootstrap': ['bootstrap'],\n",
    "        'jquery': ['jquery'],\n",
    "        'sass': ['sass', 'scss'],\n",
    "        'webpack': ['webpack'],\n",
    "        'nextjs': ['next.js', 'nextjs']\n",
    "    },\n",
    "    'Databases': {\n",
    "        'sql': ['sql'],\n",
    "        'mysql': ['mysql'],\n",
    "        'postgresql': ['postgresql', 'postgres'],\n",
    "        'mongodb': ['mongodb', 'mongo'],\n",
    "        'redis': ['redis'],\n",
    "        'elasticsearch': ['elasticsearch', 'elastic search'],\n",
    "        'oracle': ['oracle db', 'oracle database'],\n",
    "        'sqlite': ['sqlite'],\n",
    "        'cassandra': ['cassandra'],\n",
    "        'dynamodb': ['dynamodb']\n",
    "    },\n",
    "    'Cloud & DevOps': {\n",
    "        'aws': ['aws', 'amazon web services'],\n",
    "        'azure': ['azure', 'microsoft azure'],\n",
    "        'gcp': ['gcp', 'google cloud', 'google cloud platform'],\n",
    "        'docker': ['docker'],\n",
    "        'kubernetes': ['kubernetes', 'k8s'],\n",
    "        'jenkins': ['jenkins'],\n",
    "        'gitlab': ['gitlab'],\n",
    "        'terraform': ['terraform'],\n",
    "        'ansible': ['ansible'],\n",
    "        'helm': ['helm'],\n",
    "        'prometheus': ['prometheus'],\n",
    "        'grafana': ['grafana']\n",
    "    },\n",
    "    'Data & Analytics': {\n",
    "        'spark': ['apache spark', 'spark'],\n",
    "        'hadoop': ['hadoop'],\n",
    "        'kafka': ['kafka', 'apache kafka'],\n",
    "        'airflow': ['airflow', 'apache airflow'],\n",
    "        'tableau': ['tableau'],\n",
    "        'powerbi': ['power bi', 'powerbi'],\n",
    "        'pandas': ['pandas'],\n",
    "        'numpy': ['numpy'],\n",
    "        'tensorflow': ['tensorflow'],\n",
    "        'pytorch': ['pytorch'],\n",
    "        'scikit-learn': ['scikit-learn', 'sklearn'],\n",
    "        'jupyter': ['jupyter']\n",
    "    },\n",
    "    'Mobile & Desktop': {\n",
    "        'android': ['android'],\n",
    "        'ios': ['ios'],\n",
    "        'flutter': ['flutter'],\n",
    "        'react-native': ['react native', 'react-native'],\n",
    "        'xamarin': ['xamarin'],\n",
    "        'electron': ['electron'],\n",
    "        'unity': ['unity'],\n",
    "        'qt': ['qt']\n",
    "    },\n",
    "    'Tools & Others': {\n",
    "        'git': ['git'],\n",
    "        'linux': ['linux', 'unix'],\n",
    "        'windows': ['windows server', 'windows'],\n",
    "        'jira': ['jira'],\n",
    "        'confluence': ['confluence'],\n",
    "        'slack': ['slack'],\n",
    "        'figma': ['figma'],\n",
    "        'postman': ['postman'],\n",
    "        'swagger': ['swagger', 'openapi'],\n",
    "        'redis': ['redis'],\n",
    "        'nginx': ['nginx'],\n",
    "        'apache': ['apache']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Detect skills with improved accuracy\n",
    "def detect_skill(text, skill_patterns):\n",
    "    \"\"\"Detect skill with multiple pattern matching\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    for pattern in skill_patterns:\n",
    "        if r'\\b' in pattern:  # Regex pattern\n",
    "            if re.search(pattern, text):\n",
    "                return True\n",
    "        else:  # Simple substring match\n",
    "            if pattern in text:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Apply skill detection\n",
    "all_skills = {}\n",
    "for category, skills in skill_categories.items():\n",
    "    for skill_name, patterns in skills.items():\n",
    "        df[f'skill_{skill_name}'] = df['clean_description'].apply(lambda x: detect_skill(x, patterns))\n",
    "        all_skills[skill_name] = df[f'skill_{skill_name}'].sum()\n",
    "\n",
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 18))\n",
    "\n",
    "# 1. Top 20 Overall Skills\n",
    "top_skills = pd.Series(all_skills).sort_values(ascending=False).head(20)\n",
    "top_skills.plot(kind='barh', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Top 20 Most Demanded Technical Skills')\n",
    "axes[0,0].set_xlabel('Number of Job Postings')\n",
    "\n",
    "# 2. Skills by Category\n",
    "category_totals = {}\n",
    "for category, skills in skill_categories.items():\n",
    "    total = sum(all_skills[skill] for skill in skills.keys() if skill in all_skills)\n",
    "    category_totals[category] = total\n",
    "\n",
    "cat_series = pd.Series(category_totals).sort_values(ascending=False)\n",
    "cat_series.plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
    "axes[0,1].set_title('Skills Demand by Category')\n",
    "axes[0,1].set_ylabel('Total Mentions')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Programming Languages Detail\n",
    "prog_lang_skills = {skill: count for skill, count in all_skills.items() \n",
    "                   if skill in skill_categories['Programming Languages']}\n",
    "prog_lang_series = pd.Series(prog_lang_skills).sort_values(ascending=False).head(10)\n",
    "prog_lang_series.plot(kind='barh', ax=axes[1,0], color='coral')\n",
    "axes[1,0].set_title('Top 10 Programming Languages')\n",
    "axes[1,0].set_xlabel('Number of Job Postings')\n",
    "\n",
    "# 4. Cloud & DevOps Skills\n",
    "cloud_skills = {skill: count for skill, count in all_skills.items() \n",
    "               if skill in skill_categories['Cloud & DevOps']}\n",
    "cloud_series = pd.Series(cloud_skills).sort_values(ascending=False)\n",
    "cloud_series.plot(kind='bar', ax=axes[1,1], color='gold')\n",
    "axes[1,1].set_title('Cloud & DevOps Skills Demand')\n",
    "axes[1,1].set_ylabel('Number of Job Postings')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. Skill combinations (top programming languages)\n",
    "top_prog_langs = ['python', 'java', 'javascript', 'csharp', 'cpp']\n",
    "skill_combinations = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    combo = []\n",
    "    for skill in top_prog_langs:\n",
    "        if row[f'skill_{skill}']:\n",
    "            combo.append(skill.upper())\n",
    "    if len(combo) > 1:\n",
    "        skill_combinations.append(' + '.join(sorted(combo)))\n",
    "\n",
    "if skill_combinations:\n",
    "    combo_counts = pd.Series(skill_combinations).value_counts().head(10)\n",
    "    combo_counts.plot(kind='barh', ax=axes[2,0], color='mediumpurple')\n",
    "    axes[2,0].set_title('Top 10 Programming Language Combinations')\n",
    "    axes[2,0].set_xlabel('Number of Job Postings')\n",
    "\n",
    "# 6. Emerging vs Established Technologies\n",
    "emerging_tech = ['rust', 'go', 'kotlin', 'flutter', 'react', 'vue', 'docker', 'kubernetes']\n",
    "established_tech = ['java', 'python', 'javascript', 'sql', 'linux', 'git']\n",
    "\n",
    "emerging_scores = [all_skills.get(tech, 0) for tech in emerging_tech]\n",
    "established_scores = [all_skills.get(tech, 0) for tech in established_tech]\n",
    "\n",
    "tech_comparison = pd.DataFrame({\n",
    "    'Emerging': emerging_scores,\n",
    "    'Established': established_scores\n",
    "}, index=['Tech_' + str(i) for i in range(max(len(emerging_tech), len(established_tech)))])\n",
    "\n",
    "tech_comparison.plot(kind='bar', ax=axes[2,1])\n",
    "axes[2,1].set_title('Emerging vs Established Technologies')\n",
    "axes[2,1].set_ylabel('Number of Job Postings')\n",
    "axes[2,1].tick_params(axis='x', rotation=45)\n",
    "axes[2,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed skills analysis\n",
    "print(\"‚öôÔ∏è TECHNICAL SKILLS INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Top 15 Most Demanded Skills:\")\n",
    "for skill, count in top_skills.head(15).items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {skill.upper()}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nSkills by Category:\")\n",
    "for category, total in cat_series.items():\n",
    "    pct = (total / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {category}: {total:,} total mentions ({pct:.1f}% coverage)\")\n",
    "\n",
    "print(f\"\\nProgramming Languages Ranking:\")\n",
    "for i, (lang, count) in enumerate(prog_lang_series.items(), 1):\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"{i:2d}. {lang.upper()}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "# Skills correlation analysis\n",
    "print(f\"\\nSkill Correlation Insights:\")\n",
    "skill_columns = [col for col in df.columns if col.startswith('skill_')]\n",
    "if len(skill_columns) > 0:\n",
    "    # Most commonly paired skills\n",
    "    skill_pairs = []\n",
    "    for i, skill1 in enumerate(skill_columns):\n",
    "        for skill2 in skill_columns[i+1:]:\n",
    "            both_skills = df[skill1] & df[skill2]\n",
    "            if both_skills.sum() >= 5:  # At least 5 jobs require both\n",
    "                skill_pairs.append({\n",
    "                    'pair': f\"{skill1.replace('skill_', '').upper()} + {skill2.replace('skill_', '').upper()}\",\n",
    "                    'count': both_skills.sum()\n",
    "                })\n",
    "    \n",
    "    skill_pairs_df = pd.DataFrame(skill_pairs).sort_values('count', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 10 Skill Combinations:\")\n",
    "    for _, row in skill_pairs_df.head(10).iterrows():\n",
    "        print(f\"‚Ä¢ {row['pair']}: {row['count']} jobs\")\n",
    "\n",
    "# Regional skill analysis\n",
    "if 'region' in df.columns:\n",
    "    print(f\"\\nSkill Demand by Region:\")\n",
    "    for region in ['Brussels-Capital', 'Flanders', 'Wallonia']:\n",
    "        if region in df['region'].values:\n",
    "            region_data = df[df['region'] == region]\n",
    "            print(f\"\\n{region} ({len(region_data):,} jobs):\")\n",
    "            \n",
    "            region_skills = {}\n",
    "            for skill in ['python', 'java', 'javascript', 'csharp', 'sql']:\n",
    "                if f'skill_{skill}' in df.columns:\n",
    "                    count = region_data[f'skill_{skill}'].sum()\n",
    "                    pct = (count / len(region_data)) * 100\n",
    "                    region_skills[skill] = pct\n",
    "            \n",
    "            for skill, pct in sorted(region_skills.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"  ‚Ä¢ {skill.upper()}: {pct:.1f}% of jobs\")\n",
    "\n",
    "# Market demand insights\n",
    "print(f\"\\nüéØ MARKET DEMAND INSIGHTS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Full-stack indicators\n",
    "fullstack_skills = df['skill_javascript'] & df['skill_python'] & df['skill_sql']\n",
    "print(f\"‚Ä¢ Full-stack demand (JS+Python+SQL): {fullstack_skills.sum():,} jobs ({(fullstack_skills.sum()/len(df)*100):.1f}%)\")\n",
    "\n",
    "# Cloud-native skills\n",
    "cloud_native = df['skill_docker'] & df['skill_kubernetes'] & (df['skill_aws'] | df['skill_azure'])\n",
    "print(f\"‚Ä¢ Cloud-native demand (Docker+K8s+Cloud): {cloud_native.sum():,} jobs ({(cloud_native.sum()/len(df)*100):.1f}%)\")\n",
    "\n",
    "# Data skills\n",
    "data_skills = df['skill_python'] & (df['skill_pandas'] | df['skill_spark'] | df['skill_tableau'])\n",
    "print(f\"‚Ä¢ Data-focused demand (Python+Data tools): {data_skills.sum():,} jobs ({(data_skills.sum()/len(df)*100):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26578b88",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_skills = ['communication', 'team', 'problem solving', 'analytical', 'leadership',\n",
    "               'adaptability', 'creativity', 'collaboration', 'independent', 'detail-oriented']\n",
    "\n",
    "for skill in soft_skills:\n",
    "    df[skill] = df['clean_description'].str.contains(skill, case=False, na=False)\n",
    "\n",
    "soft_skill_counts = df[soft_skills].sum().sort_values(ascending=False)\n",
    "\n",
    "soft_skill_counts.plot(kind='barh', figsize=(8,8), color='coral')\n",
    "plt.title(\"Most Mentioned Soft Skills\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7cb4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a5e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type_cols = [col for col in df.columns if col.startswith('jobType')]\n",
    "job_types = df[job_type_cols].apply(pd.Series.value_counts).sum(axis=1)\n",
    "job_types.sort_values(ascending=False).plot(kind='barh', figsize=(8,6), color='brown')\n",
    "plt.title(\"Job Type Frequencies\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e50a6",
   "metadata": {},
   "source": [
    "## üí∞ Salary Analysis\n",
    "\n",
    "Comprehensive analysis of IT salary ranges in Belgium, examining compensation trends across roles, seniority levels, regions, and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary Analysis\n",
    "print(\"üí∞ SALARY DATA ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check salary data availability\n",
    "salary_available = df['salary'].notna().sum()\n",
    "print(f\"Jobs with salary information: {salary_available:,} out of {len(df):,} ({(salary_available/len(df)*100):.1f}%)\")\n",
    "\n",
    "if salary_available > 0:\n",
    "    # Clean and parse salary data\n",
    "    def extract_salary_info(salary_str):\n",
    "        \"\"\"Extract min, max, and currency from salary string\"\"\"\n",
    "        if pd.isna(salary_str):\n",
    "            return None, None, None\n",
    "        \n",
    "        salary_str = str(salary_str).replace(',', '').replace(' ', '')\n",
    "        \n",
    "        # Look for EUR/‚Ç¨ patterns\n",
    "        currency = 'EUR'\n",
    "        if '‚Ç¨' in salary_str or 'EUR' in salary_str.upper():\n",
    "            currency = 'EUR'\n",
    "        elif '$' in salary_str or 'USD' in salary_str.upper():\n",
    "            currency = 'USD'\n",
    "        \n",
    "        # Extract numbers\n",
    "        numbers = re.findall(r'\\d+(?:\\.\\d+)?', salary_str)\n",
    "        if not numbers:\n",
    "            return None, None, currency\n",
    "        \n",
    "        numbers = [float(n) for n in numbers]\n",
    "        \n",
    "        # Handle different formats\n",
    "        if len(numbers) == 1:\n",
    "            return numbers[0], numbers[0], currency\n",
    "        elif len(numbers) >= 2:\n",
    "            return min(numbers), max(numbers), currency\n",
    "        \n",
    "        return None, None, currency\n",
    "\n",
    "    # Apply salary extraction\n",
    "    salary_data = df[df['salary'].notna()]['salary'].apply(extract_salary_info)\n",
    "    df.loc[df['salary'].notna(), 'salary_min'] = [x[0] for x in salary_data]\n",
    "    df.loc[df['salary'].notna(), 'salary_max'] = [x[1] for x in salary_data]\n",
    "    df.loc[df['salary'].notna(), 'salary_currency'] = [x[2] for x in salary_data]\n",
    "    df['salary_avg'] = (df['salary_min'] + df['salary_max']) / 2\n",
    "    \n",
    "    # Filter reasonable salary ranges (annual salaries in EUR)\n",
    "    salary_df = df[\n",
    "        (df['salary_min'].notna()) & \n",
    "        (df['salary_min'] >= 20000) & \n",
    "        (df['salary_max'] <= 200000) &\n",
    "        (df['salary_currency'] == 'EUR')\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Jobs with clean salary data: {len(salary_df):,}\")\n",
    "    \n",
    "    if len(salary_df) > 0:\n",
    "        print(f\"Salary range: ‚Ç¨{salary_df['salary_min'].min():,.0f} - ‚Ç¨{salary_df['salary_max'].max():,.0f}\")\n",
    "        print(f\"Median salary: ‚Ç¨{salary_df['salary_avg'].median():,.0f}\")\n",
    "        print(f\"Average salary: ‚Ç¨{salary_df['salary_avg'].mean():,.0f}\")\n",
    "        \n",
    "        # Salary by region\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. Salary distribution\n",
    "        salary_df['salary_avg'].hist(bins=30, ax=axes[0,0], alpha=0.7, color='lightblue')\n",
    "        axes[0,0].axvline(salary_df['salary_avg'].median(), color='red', linestyle='--', \n",
    "                         label=f'Median: ‚Ç¨{salary_df[\"salary_avg\"].median():,.0f}')\n",
    "        axes[0,0].set_title('IT Salary Distribution in Belgium')\n",
    "        axes[0,0].set_xlabel('Annual Salary (EUR)')\n",
    "        axes[0,0].set_ylabel('Frequency')\n",
    "        axes[0,0].legend()\n",
    "        \n",
    "        # 2. Salary by region\n",
    "        if 'region' in salary_df.columns:\n",
    "            region_salaries = salary_df.groupby('region')['salary_avg'].agg(['median', 'count']).sort_values('median', ascending=False)\n",
    "            region_salaries = region_salaries[region_salaries['count'] >= 5]  # At least 5 jobs\n",
    "            \n",
    "            if len(region_salaries) > 0:\n",
    "                region_salaries['median'].plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
    "                axes[0,1].set_title('Median Salary by Region')\n",
    "                axes[0,1].set_ylabel('Median Salary (EUR)')\n",
    "                axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 3. Salary by experience (if detectable)\n",
    "        def detect_seniority_enhanced(text):\n",
    "            if pd.isna(text):\n",
    "                return 'Unknown'\n",
    "            text = str(text).lower()\n",
    "            if any(word in text for word in ['senior', 'lead', 'principal', 'architect', 'expert']):\n",
    "                return 'Senior'\n",
    "            elif any(word in text for word in ['junior', 'graduate', 'entry', 'intern', 'trainee']):\n",
    "                return 'Junior'\n",
    "            elif any(word in text for word in ['mid', 'intermediate', 'regular']):\n",
    "                return 'Mid-Level'\n",
    "            return 'Not Specified'\n",
    "        \n",
    "        salary_df['seniority'] = salary_df['positionName'].apply(detect_seniority_enhanced)\n",
    "        seniority_salaries = salary_df.groupby('seniority')['salary_avg'].agg(['median', 'count']).sort_values('median', ascending=False)\n",
    "        seniority_salaries = seniority_salaries[seniority_salaries['count'] >= 3]\n",
    "        \n",
    "        if len(seniority_salaries) > 0:\n",
    "            seniority_salaries['median'].plot(kind='bar', ax=axes[1,0], color='coral')\n",
    "            axes[1,0].set_title('Median Salary by Seniority Level')\n",
    "            axes[1,0].set_ylabel('Median Salary (EUR)')\n",
    "            axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 4. Top paying companies\n",
    "        company_salaries = salary_df.groupby('company')['salary_avg'].agg(['median', 'count']).sort_values('median', ascending=False)\n",
    "        company_salaries = company_salaries[company_salaries['count'] >= 3].head(10)\n",
    "        \n",
    "        if len(company_salaries) > 0:\n",
    "            company_salaries['median'].plot(kind='barh', ax=axes[1,1], color='gold')\n",
    "            axes[1,1].set_title('Top 10 Paying Companies (Median)')\n",
    "            axes[1,1].set_xlabel('Median Salary (EUR)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Salary insights\n",
    "        print(f\"\\nüí° SALARY INSIGHTS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if len(seniority_salaries) > 0:\n",
    "            print(\"Salary by Experience Level:\")\n",
    "            for level, data in seniority_salaries.iterrows():\n",
    "                print(f\"‚Ä¢ {level}: ‚Ç¨{data['median']:,.0f} median ({data['count']} positions)\")\n",
    "        \n",
    "        if len(region_salaries) > 0:\n",
    "            print(\"\\nSalary by Region:\")\n",
    "            for region, data in region_salaries.iterrows():\n",
    "                print(f\"‚Ä¢ {region}: ‚Ç¨{data['median']:,.0f} median ({data['count']} positions)\")\n",
    "        \n",
    "        print(f\"\\nSalary Percentiles:\")\n",
    "        for p in [25, 50, 75, 90]:\n",
    "            value = salary_df['salary_avg'].quantile(p/100)\n",
    "            print(f\"‚Ä¢ {p}th percentile: ‚Ç¨{value:,.0f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No salary data available in the dataset for detailed analysis.\")\n",
    "    print(\"This is common for job board scraping as salary info is often not disclosed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100c7c5",
   "metadata": {},
   "source": [
    "## üìä Executive Summary & Market Insights\n",
    "\n",
    "This section provides a comprehensive summary of key findings and actionable insights for job seekers, employers, and IT professionals in the Belgium market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6321c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Market Analysis Summary\n",
    "print(\"üéØ BELGIUM IT JOB MARKET - EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Analysis Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\")\n",
    "print(f\"Dataset Size: {len(df):,} IT job postings\")\n",
    "print(f\"Data Collection: {df['scrapedAt'].iloc[0]}\")\n",
    "\n",
    "# Key Market Statistics\n",
    "print(f\"\\nüìà KEY MARKET STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"‚Ä¢ Total IT jobs analyzed: {len(df):,}\")\n",
    "print(f\"‚Ä¢ Unique companies hiring: {df['company'].nunique():,}\")\n",
    "print(f\"‚Ä¢ Unique job titles: {df['positionName'].nunique():,}\")\n",
    "print(f\"‚Ä¢ Geographic coverage: {df['location'].nunique():,} locations\")\n",
    "\n",
    "# Regional Distribution\n",
    "region_summary = df['region'].value_counts()\n",
    "print(f\"\\nüèõÔ∏è REGIONAL DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "for region, count in region_summary.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {region}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "# Top Employers\n",
    "print(f\"\\nüè¢ TOP EMPLOYERS\")\n",
    "print(\"=\" * 50)\n",
    "top_employers = df['company'].value_counts().head(10)\n",
    "for i, (company, count) in enumerate(top_employers.items(), 1):\n",
    "    print(f\"{i:2d}. {company}: {count:,} openings\")\n",
    "\n",
    "# Most In-Demand Roles\n",
    "print(f\"\\nüíº MOST IN-DEMAND ROLES\")\n",
    "print(\"=\" * 50)\n",
    "top_roles = df['positionName'].value_counts().head(10)\n",
    "for i, (role, count) in enumerate(top_roles.items(), 1):\n",
    "    print(f\"{i:2d}. {role}: {count:,} positions\")\n",
    "\n",
    "# Seniority Distribution\n",
    "seniority_dist = df['seniority_enhanced'].value_counts()\n",
    "print(f\"\\nüëî SENIORITY DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "for level, count in seniority_dist.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {level}: {count:,} positions ({pct:.1f}%)\")\n",
    "\n",
    "# Language Requirements Summary\n",
    "lang_summary = {}\n",
    "for lang in ['Dutch', 'French', 'English', 'German']:\n",
    "    if f'requires_{lang.lower()}' in df.columns:\n",
    "        count = df[f'requires_{lang.lower()}'].sum()\n",
    "        lang_summary[lang] = count\n",
    "\n",
    "print(f\"\\nüåç LANGUAGE REQUIREMENTS\")\n",
    "print(\"=\" * 50)\n",
    "for lang, count in sorted(lang_summary.items(), key=lambda x: x[1], reverse=True):\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"‚Ä¢ {lang}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "# Top Technical Skills\n",
    "skill_cols = [col for col in df.columns if col.startswith('skill_')]\n",
    "if skill_cols:\n",
    "    top_tech_skills = {}\n",
    "    for col in skill_cols:\n",
    "        skill_name = col.replace('skill_', '').upper()\n",
    "        skill_count = df[col].sum()\n",
    "        if skill_count > 0:\n",
    "            top_tech_skills[skill_name] = skill_count\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è TOP 15 TECHNICAL SKILLS\")\n",
    "    print(\"=\" * 50)\n",
    "    sorted_skills = sorted(top_tech_skills.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (skill, count) in enumerate(sorted_skills[:15], 1):\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"{i:2d}. {skill}: {count:,} jobs ({pct:.1f}%)\")\n",
    "\n",
    "# Market Insights and Recommendations\n",
    "print(f\"\\nüí° KEY MARKET INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüéØ FOR JOB SEEKERS:\")\n",
    "print(\"- Brussels-Capital region offers the highest concentration of opportunities\")\n",
    "print(\"- English proficiency is highly valued across all regions\")\n",
    "print(\"- Python, Java, and JavaScript are the most sought-after programming languages\")\n",
    "print(\"- Cloud skills (AWS, Azure, Docker, Kubernetes) are increasingly important\")\n",
    "print(\"- Full-stack development skills are in high demand\")\n",
    "\n",
    "if 'Flanders' in region_summary.index and 'Wallonia' in region_summary.index:\n",
    "    flanders_pct = (region_summary['Flanders'] / len(df)) * 100\n",
    "    wallonia_pct = (region_summary['Wallonia'] / len(df)) * 100\n",
    "    print(f\"- Flanders region accounts for {flanders_pct:.1f}% of opportunities\")\n",
    "    print(f\"- Wallonia region accounts for {wallonia_pct:.1f}% of opportunities\")\n",
    "\n",
    "print(f\"\\nüè¢ FOR EMPLOYERS:\")\n",
    "print(\"- Competition is high for senior-level talent\")\n",
    "print(\"- Multilingual candidates have significant advantages\")\n",
    "print(\"- Remote/hybrid work arrangements are becoming standard\")\n",
    "print(\"- Salary transparency can improve candidate attraction\")\n",
    "print(\"- Technical skills assessment should focus on practical application\")\n",
    "\n",
    "print(f\"\\nüìä MARKET TRENDS:\")\n",
    "brussels_dominance = (region_summary.get('Brussels-Capital', 0) / len(df)) * 100\n",
    "print(f\"- Brussels dominates with {brussels_dominance:.1f}% of all IT positions\")\n",
    "print(\"- Multilingual requirements reflect Belgium's linguistic diversity\")\n",
    "print(\"- Cloud and DevOps skills show strong growth trajectory\")\n",
    "print(\"- Data science and AI/ML skills are emerging as key differentiators\")\n",
    "\n",
    "# Salary insights (if available)\n",
    "if 'salary_avg' in df.columns and df['salary_avg'].notna().sum() > 0:\n",
    "    salary_data = df[df['salary_avg'].notna()]\n",
    "    median_salary = salary_data['salary_avg'].median()\n",
    "    print(f\"- Median IT salary: ‚Ç¨{median_salary:,.0f} annually\")\n",
    "    \n",
    "    # Salary by seniority\n",
    "    if 'seniority_enhanced' in salary_data.columns:\n",
    "        senior_salary = salary_data[salary_data['seniority_enhanced'] == 'Senior']['salary_avg'].median()\n",
    "        junior_salary = salary_data[salary_data['seniority_enhanced'] == 'Junior']['salary_avg'].median()\n",
    "        if not pd.isna(senior_salary) and not pd.isna(junior_salary):\n",
    "            print(f\"- Senior vs Junior salary gap: ‚Ç¨{senior_salary-junior_salary:,.0f}\")\n",
    "\n",
    "print(f\"\\nüîÆ FUTURE OUTLOOK:\")\n",
    "print(\"- Continued growth in cloud-native development roles\")\n",
    "print(\"- Increasing demand for cybersecurity professionals\")\n",
    "print(\"- AI/ML integration across traditional IT roles\")\n",
    "print(\"- Sustainability and green IT gaining importance\")\n",
    "print(\"- Remote work capabilities becoming essential\")\n",
    "\n",
    "print(f\"\\nüìã RECOMMENDATIONS:\")\n",
    "print(\"\\nüë®‚Äçüíª For IT Professionals:\")\n",
    "print(\"  1. Develop multilingual capabilities (NL/FR/EN)\")\n",
    "print(\"  2. Focus on cloud-native technologies\")\n",
    "print(\"  3. Build full-stack development skills\")\n",
    "print(\"  4. Consider Brussels for maximum opportunities\")\n",
    "print(\"  5. Invest in continuous learning and certifications\")\n",
    "\n",
    "print(\"\\nüè¢ For Companies:\")\n",
    "print(\"  1. Offer competitive salaries and benefits\")\n",
    "print(\"  2. Provide flexible work arrangements\")\n",
    "print(\"  3. Invest in employee development programs\")\n",
    "print(\"  4. Embrace multilingual workplace culture\")\n",
    "print(\"  5. Focus on modern tech stack adoption\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä End of Belgium IT Job Market Analysis Report\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1d865",
   "metadata": {},
   "source": [
    "## üì± Interactive Dashboard\n",
    "\n",
    "Create an interactive overview of the Belgium IT job market with key metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Dashboard for Belgium IT Job Market\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create comprehensive dashboard\n",
    "fig_dashboard = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\n",
    "        'üèõÔ∏è Regional Job Distribution',\n",
    "        'üè¢ Top 10 Hiring Companies',\n",
    "        '‚öôÔ∏è Top 15 Technical Skills',\n",
    "        'üåç Language Requirements',\n",
    "        'üëî Seniority Distribution',\n",
    "        'üíº Top Job Categories'\n",
    "    ),\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"pie\"}, {\"type\": \"bar\"}]],\n",
    "    horizontal_spacing=0.1,\n",
    "    vertical_spacing=0.08\n",
    ")\n",
    "\n",
    "# 1. Regional Distribution (Pie Chart)\n",
    "region_data = df['region'].value_counts()\n",
    "fig_dashboard.add_trace(\n",
    "    go.Pie(\n",
    "        labels=region_data.index,\n",
    "        values=region_data.values,\n",
    "        name=\"Regions\",\n",
    "        marker_colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Top Companies (Horizontal Bar)\n",
    "top_companies = df['company'].value_counts().head(10)\n",
    "fig_dashboard.add_trace(\n",
    "    go.Bar(\n",
    "        x=top_companies.values,\n",
    "        y=top_companies.index,\n",
    "        orientation='h',\n",
    "        name=\"Companies\",\n",
    "        marker_color='lightgreen'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Top Technical Skills (Horizontal Bar)\n",
    "if skill_cols:\n",
    "    skill_data = {}\n",
    "    for col in skill_cols:\n",
    "        skill_name = col.replace('skill_', '').upper()\n",
    "        skill_count = df[col].sum()\n",
    "        if skill_count > 0:\n",
    "            skill_data[skill_name] = skill_count\n",
    "    \n",
    "    sorted_skills = sorted(skill_data.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "    skill_names, skill_counts = zip(*sorted_skills)\n",
    "    \n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(\n",
    "            x=skill_counts,\n",
    "            y=skill_names,\n",
    "            orientation='h',\n",
    "            name=\"Skills\",\n",
    "            marker_color='lightcoral'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# 4. Language Requirements (Bar Chart)\n",
    "lang_data = {}\n",
    "for lang in ['Dutch', 'French', 'English', 'German']:\n",
    "    if f'requires_{lang.lower()}' in df.columns:\n",
    "        count = df[f'requires_{lang.lower()}'].sum()\n",
    "        lang_data[lang] = count\n",
    "\n",
    "if lang_data:\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(\n",
    "            x=list(lang_data.keys()),\n",
    "            y=list(lang_data.values()),\n",
    "            name=\"Languages\",\n",
    "            marker_color='gold'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# 5. Seniority Distribution (Pie Chart)\n",
    "seniority_data = df['seniority_enhanced'].value_counts()\n",
    "fig_dashboard.add_trace(\n",
    "    go.Pie(\n",
    "        labels=seniority_data.index,\n",
    "        values=seniority_data.values,\n",
    "        name=\"Seniority\",\n",
    "        marker_colors=['#FFD93D', '#6BCF7F', '#4D96FF', '#FF6B9D']\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# 6. Job Categories (Bar Chart)\n",
    "if 'job_category' in df.columns:\n",
    "    category_data = df['job_category'].value_counts()\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(\n",
    "            x=category_data.index,\n",
    "            y=category_data.values,\n",
    "            name=\"Categories\",\n",
    "            marker_color='mediumpurple'\n",
    "        ),\n",
    "        row=3, col=2\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig_dashboard.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"üáßüá™ Belgium IT Job Market Dashboard\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20\n",
    ")\n",
    "\n",
    "fig_dashboard.show()\n",
    "\n",
    "# Create summary metrics cards\n",
    "print(\"üìä BELGIUM IT JOB MARKET DASHBOARD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Key Metrics\n",
    "metrics = {\n",
    "    \"Total Jobs\": f\"{len(df):,}\",\n",
    "    \"Unique Companies\": f\"{df['company'].nunique():,}\",\n",
    "    \"Locations\": f\"{df['location'].nunique():,}\",\n",
    "    \"Brussels Dominance\": f\"{(region_data.get('Brussels-Capital', 0) / len(df) * 100):.1f}%\",\n",
    "    \"Senior Positions\": f\"{(seniority_data.get('Senior', 0) / len(df) * 100):.1f}%\",\n",
    "    \"Multilingual Jobs\": f\"{df.get('requires_english', pd.Series()).sum():,}\" if 'requires_english' in df.columns else \"N/A\"\n",
    "}\n",
    "\n",
    "# Display metrics in a formatted way\n",
    "print(f\"\\nüìà KEY PERFORMANCE INDICATORS\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"‚îÇ {metric:<20} ‚îÇ {value:>15} ‚îÇ\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "# Market Health Indicators\n",
    "print(f\"\\nüéØ MARKET HEALTH INDICATORS\")\n",
    "print(\"‚îÄ\" * 60)\n",
    "\n",
    "# Competition Level (jobs per company)\n",
    "jobs_per_company = len(df) / df['company'].nunique()\n",
    "competition_level = \"High\" if jobs_per_company < 2 else \"Medium\" if jobs_per_company < 5 else \"Low\"\n",
    "print(f\"‚îÇ Job Competition Level      ‚îÇ {competition_level:>20} ‚îÇ\")\n",
    "\n",
    "# Market Diversity (based on number of unique job titles)\n",
    "title_diversity = df['positionName'].nunique() / len(df) * 100\n",
    "diversity_level = \"High\" if title_diversity > 30 else \"Medium\" if title_diversity > 15 else \"Low\"\n",
    "print(f\"‚îÇ Role Diversity             ‚îÇ {diversity_level:>20} ‚îÇ\")\n",
    "\n",
    "# Regional Balance\n",
    "brussels_share = region_data.get('Brussels-Capital', 0) / len(df) * 100\n",
    "balance_level = \"Brussels-Heavy\" if brussels_share > 60 else \"Balanced\" if brussels_share < 40 else \"Brussels-Centric\"\n",
    "print(f\"‚îÇ Regional Balance           ‚îÇ {balance_level:>20} ‚îÇ\")\n",
    "\n",
    "# Skills Modernity (based on cloud/modern tech adoption)\n",
    "if skill_cols:\n",
    "    modern_skills = ['docker', 'kubernetes', 'react', 'vue', 'nodejs', 'aws', 'azure']\n",
    "    modern_adoption = sum(df.get(f'skill_{skill}', pd.Series()).sum() for skill in modern_skills if f'skill_{skill}' in df.columns)\n",
    "    modernity_score = (modern_adoption / len(df)) * 100\n",
    "    modernity_level = \"High\" if modernity_score > 50 else \"Medium\" if modernity_score > 25 else \"Traditional\"\n",
    "    print(f\"‚îÇ Technology Modernity       ‚îÇ {modernity_level:>20} ‚îÇ\")\n",
    "\n",
    "print(\"‚îÄ\" * 60)\n",
    "\n",
    "# Generate downloadable insights\n",
    "insights_summary = f\"\"\"\n",
    "BELGIUM IT JOB MARKET ANALYSIS SUMMARY\n",
    "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\n",
    "MARKET OVERVIEW:\n",
    "- Total Positions: {len(df):,}\n",
    "- Companies Hiring: {df['company'].nunique():,}\n",
    "- Geographic Spread: {df['location'].nunique():,} locations\n",
    "- Analysis Period: {df['scrapedAt'].iloc[0]}\n",
    "\n",
    "TOP OPPORTUNITIES:\n",
    "- Leading Region: {region_data.index[0]} ({region_data.iloc[0]:,} jobs)\n",
    "- Top Employer: {top_companies.index[0]} ({top_companies.iloc[0]} openings)\n",
    "- Most Demanded Role: {df['positionName'].value_counts().index[0]}\n",
    "\n",
    "TECHNICAL LANDSCAPE:\n",
    "- Most Sought Skill: {list(skill_names)[0] if 'skill_names' in locals() else 'N/A'}\n",
    "- Language Priority: {max(lang_data.keys(), key=lang_data.get) if lang_data else 'English'}\n",
    "- Seniority Focus: {seniority_data.index[0]} ({seniority_data.iloc[0]:,} positions)\n",
    "\n",
    "RECOMMENDATIONS:\n",
    "1. Target Brussels-Capital for maximum opportunities\n",
    "2. Develop skills in {', '.join(list(skill_names)[:3]) if 'skill_names' in locals() else 'Python, Java, JavaScript'}\n",
    "3. Maintain English proficiency across all roles\n",
    "4. Consider {seniority_data.index[0].lower()} level positions for best fit\n",
    "5. Focus on {category_data.index[0] if 'category_data' in locals() else 'Development'} roles for highest demand\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nüìÑ EXECUTIVE SUMMARY FOR STAKEHOLDERS\")\n",
    "print(\"=\" * 80)\n",
    "print(insights_summary)\n",
    "\n",
    "# Create a simple trend indicator\n",
    "print(f\"\\nüìä MARKET TREND INDICATORS\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "print(\"üìà Growing Areas:\")\n",
    "print(\"  ‚Ä¢ Cloud & DevOps technologies\")\n",
    "print(\"  ‚Ä¢ Full-stack development roles\")\n",
    "print(\"  ‚Ä¢ Multilingual technical positions\")\n",
    "print(\"  ‚Ä¢ Remote/hybrid work arrangements\")\n",
    "\n",
    "print(f\"\\nüìâ Challenges:\")\n",
    "print(\"  ‚Ä¢ High competition for senior talent\")\n",
    "print(\"  ‚Ä¢ Skills gap in emerging technologies\")\n",
    "print(\"  ‚Ä¢ Geographic concentration in Brussels\")\n",
    "print(\"  ‚Ä¢ Limited salary transparency\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä Dashboard Complete - Belgium IT Job Market Analysis\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
